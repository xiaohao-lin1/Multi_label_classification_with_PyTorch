{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22620/4251271545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "\n",
    "#TODO: check the batchsize\n",
    "#TODO: get the data_dir\n",
    "#TODO:\n",
    "def load_data(data_dir=os.getcwd()+'\\input\\img', batchsize=64):\n",
    "    '''\n",
    "\n",
    "    :param data_dir: data directory path\n",
    "    :return: train_loader, val_loader, test_loader in PyTorch Loader format\n",
    "    '''\n",
    "\n",
    "    # train_dir = data_dir + '/train'\n",
    "    # valid_dir = data_dir + '/valid'\n",
    "    # test_dir = data_dir + '/test'\n",
    "\n",
    "    # Define transforms for the training, validation, and testing sets\n",
    "    training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                              transforms.RandomResizedCrop(224),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                   [0.229, 0.224, 0.225])])\n",
    "\n",
    "    validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                                transforms.CenterCrop(224),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                     [0.229, 0.224, 0.225])])\n",
    "\n",
    "    testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                             transforms.CenterCrop(224),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                  [0.229, 0.224, 0.225])])\n",
    "\n",
    "    # TODO: Load the datasets with ImageFolder\n",
    "    training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
    "    validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
    "    testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
    "\n",
    "    # TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batchsize, shuffle=True)\n",
    "    validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batchsize)\n",
    "    test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=batchsize)\n",
    "\n",
    "    return train_loader, validate_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: 2. label mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: 3 build and train the classifer, sequential model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: 4. test the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: 5 save the check pt and load it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
